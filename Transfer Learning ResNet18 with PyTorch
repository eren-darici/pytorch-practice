{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGzCR1b7V4H6dSAu5xbEeX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"id":"gU4bOu1XLXvR","executionInfo":{"status":"ok","timestamp":1689621221039,"user_tz":-180,"elapsed":2,"user":{"displayName":"Eren DARICI","userId":"16164594222995643781"}}},"outputs":[],"source":["# Imports\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from torch.optim import lr_scheduler\n","import time\n","import os\n","import copy\n","import numpy as np"]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POtRthGAQnNh","executionInfo":{"status":"ok","timestamp":1689621223051,"user_tz":-180,"elapsed":1787,"user":{"displayName":"Eren DARICI","userId":"16164594222995643781"}},"outputId":"52bd93ab-f094-4fc5-9273-26fa6220b748"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"XCmGhhNdLu37","executionInfo":{"status":"ok","timestamp":1689621223052,"user_tz":-180,"elapsed":3,"user":{"displayName":"Eren DARICI","userId":"16164594222995643781"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Data transforms\n","mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])\n","\n","data_transforms ={\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","}"],"metadata":{"id":"suIAl120LvzH","executionInfo":{"status":"ok","timestamp":1689621223052,"user_tz":-180,"elapsed":3,"user":{"displayName":"Eren DARICI","userId":"16164594222995643781"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Import data\n","data_dir = '/content/drive/MyDrive/Datasets/hymenoptera_data'\n","sets = ['train', 'val']\n","\n","image_datasets =  {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in sets}\n","\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=0) for x in sets}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in sets}\n","class_names = image_datasets['train'].classes\n","print(class_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDoOnTnHMfCi","executionInfo":{"status":"ok","timestamp":1689621235677,"user_tz":-180,"elapsed":3,"user":{"displayName":"Eren DARICI","userId":"16164594222995643781"}},"outputId":"50ff08c5-2911-4e7d-c956-b3be4aed4ff6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["['ants', 'bees']\n"]}]},{"cell_type":"code","source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        optimizer.zero_grad()\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"metadata":{"id":"IJHXfg1iMyrA","executionInfo":{"status":"ok","timestamp":1689621238507,"user_tz":-180,"elapsed":3,"user":{"displayName":"Eren DARICI","userId":"16164594222995643781"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# ResNet18\n","model_conv = torchvision.models.resnet18(pretrained=True)\n","for param in model_conv.parameters():\n","    param.requires_grad = False\n","\n","# Parameters of newly constructed modules have requires_grad=True by default\n","num_ftrs = model_conv.fc.in_features\n","model_conv.fc = nn.Linear(num_ftrs, 2)\n","\n","model_conv = model_conv.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer_conv = torch.optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n","\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n","\n","model_conv = train_model(model_conv, criterion, optimizer_conv,\n","                         exp_lr_scheduler, num_epochs=2)"],"metadata":{"id":"gCzRadJYQE7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689621885871,"user_tz":-180,"elapsed":110881,"user":{"displayName":"Eren DARICI","userId":"16164594222995643781"}},"outputId":"966c48ac-a638-4b4a-ff9a-5b6e0893f71c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/1\n","----------\n","train Loss: 0.6020 Acc: 0.6721\n","val Loss: 0.2109 Acc: 0.9388\n","\n","Epoch 1/1\n","----------\n","train Loss: 0.3624 Acc: 0.8402\n","val Loss: 0.1926 Acc: 0.9320\n","\n","Training complete in 1m 50s\n","Best val Acc: 0.938776\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xLrJhuOaRtA0"},"execution_count":null,"outputs":[]}]}